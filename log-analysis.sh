#!/bin/bash

echo "=========================================="
echo "SLURM Log File Analysis"
echo "=========================================="
echo "Generated: $(date)"
echo ""

# Use JOB_WORKDIR if set, otherwise current directory
WORK_DIR="${JOB_WORKDIR:-$(pwd)}"
echo "Working directory: $WORK_DIR"
echo ""

# Count log files by extension
OUT_FILES=$(ls "$WORK_DIR"/*.out 2>/dev/null | wc -l)
ERR_FILES=$(ls "$WORK_DIR"/*.err 2>/dev/null | wc -l)
LOG_FILES=$(ls "$WORK_DIR"/*.log 2>/dev/null | wc -l)

echo "ğŸ“„ LOG FILE SUMMARY"
echo "----------------------------------------"
echo "ğŸ“ Output files (.out): $OUT_FILES"
echo "âš ï¸  Error files (.err): $ERR_FILES"
echo "ğŸ“‹ Log files (.log): $LOG_FILES"
echo ""

# Check for errors in stderr files
echo "ğŸš¨ ERROR ANALYSIS"
echo "----------------------------------------"
if [ $ERR_FILES -gt 0 ]; then
    echo "ğŸ” Checking error files for issues..."
    
    # Count files with actual errors (non-empty)
    NON_EMPTY_ERRORS=$(find "$WORK_DIR" -name "*.err" -size +0 | wc -l)
    echo "ğŸ“Š Files with error output: $NON_EMPTY_ERRORS"
    
    if [ $NON_EMPTY_ERRORS -gt 0 ]; then
        echo ""
        echo "ğŸ” Sample errors (first 5 files with errors):"
        find "$WORK_DIR" -name "*.err" -size +0 | head -5 | while read file; do
            echo "ğŸ“ $(basename $file):"
            head -3 "$file" | sed 's/^/   /'
            echo ""
        done
        
        echo "ğŸ·ï¸  Common error patterns:"
        cat "$WORK_DIR"/*.err 2>/dev/null | grep -i "error\|exception\|failed\|timeout" | sort | uniq -c | sort -nr | head -10
    else
        echo "âœ… No errors found in stderr files!"
    fi
else
    echo "â„¹ï¸  No error files found"
fi

echo ""

# Check output files for completion messages
echo "âœ… COMPLETION ANALYSIS"
echo "----------------------------------------"
if [ $OUT_FILES -gt 0 ]; then
    SUCCESSFUL_COMPLETIONS=$(grep -l "successfully\|completed\|finished" "$WORK_DIR"/*.out 2>/dev/null | wc -l)
    echo "ğŸ¯ Jobs with completion messages: $SUCCESSFUL_COMPLETIONS"
    
    # Check for timeout or kill messages
    TIMEOUTS=$(grep -l "timeout\|killed\|terminated" "$WORK_DIR"/*.out 2>/dev/null | wc -l)
    echo "â° Jobs with timeout/kill messages: $TIMEOUTS"
    
    # Check for memory issues
    MEMORY_ISSUES=$(grep -l "memory\|oom\|killed" "$WORK_DIR"/*.err 2>/dev/null | wc -l)
    echo "ğŸ’¾ Jobs with memory issues: $MEMORY_ISSUES"
    
    echo ""
    echo "ğŸ“Š Recent log file activity:"
    ls -lt "$WORK_DIR"/*.{out,err,log} 2>/dev/null | head -5
else
    echo "â„¹ï¸  No output files found"
fi

echo ""

# Performance insights from logs
echo "ğŸš€ PERFORMANCE INSIGHTS FROM LOGS"
echo "----------------------------------------"

# Look for processing time information in both .out and .log files
if [ $OUT_FILES -gt 0 ] || [ $LOG_FILES -gt 0 ]; then
    echo "â±ï¸  Processing times found in logs:"
    
    # Check .out files
    if [ $OUT_FILES -gt 0 ]; then
        grep -h "processed\|took\|elapsed\|duration" "$WORK_DIR"/*.out 2>/dev/null | head -3 | sed 's/^/   OUT: /'
    fi
    
    # Check .log files (your Python processor logs)
    if [ $LOG_FILES -gt 0 ]; then
        grep -h "processed\|took\|elapsed\|duration\|time" "$WORK_DIR"/*.log 2>/dev/null | head -3 | sed 's/^/   LOG: /'
    fi
fi

echo ""

# Analysis of Python processor logs
if [ $LOG_FILES -gt 0 ]; then
    echo "ğŸ PYTHON PROCESSOR LOG ANALYSIS"
    echo "----------------------------------------"
    
    # Look for successful processing patterns
    SUCCESS_PATTERNS=$(grep -c "success\|complete\|finished\|processed.*files" "$WORK_DIR"/*.log 2>/dev/null | grep -v ":0" | wc -l)
    echo "ğŸ“Š Logs with success indicators: $SUCCESS_PATTERNS"
    
    # Look for common error patterns in Python logs
    PYTHON_ERRORS=$(grep -l "ERROR\|Exception\|Traceback\|Failed" "$WORK_DIR"/*.log 2>/dev/null | wc -l)
    echo "ğŸ› Logs with Python errors: $PYTHON_ERRORS"
    
    if [ $PYTHON_ERRORS -gt 0 ]; then
        echo ""
        echo "ğŸ” Sample Python errors:"
        grep -h "ERROR\|Exception" "$WORK_DIR"/*.log 2>/dev/null | head -3 | sed 's/^/   /'
    fi
fi

echo ""

# File size analysis
echo "ğŸ“Š FILE SIZE ANALYSIS"
echo "----------------------------------------"
if [ $OUT_FILES -gt 0 ] || [ $ERR_FILES -gt 0 ] || [ $LOG_FILES -gt 0 ]; then
    echo "ğŸ’¾ Total log space usage:"
    du -sh "$WORK_DIR"/*.{out,err,log} 2>/dev/null | awk '{total+=$1} END {print "   Total: " total}'
    
    echo ""
    echo "ğŸ“ Largest log files:"
    ls -lSh "$WORK_DIR"/*.{out,err,log} 2>/dev/null | head -5 | awk '{print "   " $9 " (" $5 ")"}'
fi

echo ""
echo "=========================================="
echo "ğŸ’¡ Additional log analysis commands:"
echo "   ğŸ” Search for specific error: grep -r 'error_text' $WORK_DIR/*.err"
echo "   ğŸ“Š Count specific patterns: grep -c 'pattern' $WORK_DIR/*.out"
echo "   ğŸ“ View specific log: less $WORK_DIR/FILENAME.{out,err,log}"
echo "   ğŸ—‘ï¸  Clean old logs: rm $WORK_DIR/*.{out,err,log}"
echo "   ğŸ Check Python logs: grep -i error $WORK_DIR/*.log"
echo "   ğŸ“ˆ Monitor real-time: tail -f $WORK_DIR/*.log"
echo "=========================================="
